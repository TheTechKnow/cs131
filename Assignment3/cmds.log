   66  find/ etc/ -type f -name "*.txt"
   67  ls
   68  cat cs131
   69  cd cs131
   70  ls
   71  cat Worksheet2
   72  cd Worksheet2
   73  ls
   74  cat counts.txt
   75  cmds.lod
   76  cat cmds.log
   77  git remote set-url origin git@github.com:TheTechKnow/cs131.git
   78  git push origin main
   79  git remote add origin git@github.com:TheTechKnow/cs131.git
   80  git push --set-upstream origin main
   81  git config --global user.email "gursimran30kaur@gmail.com"
   82  git config --global user.name "TheTechKnow"
   83  git remote add origin git@github.com:TheTechKnow/cs131.git
   84  git push origin main
   85  exit
   86  cat cs131
   87  cd cs131
   88  exit
   89  script
   90  cd cs 131
   91  cd cs131
   92  mkdir Assignment1
   93  cd Assignment1
   94  vi
   95  vi cdms.log
   96  vi cmds.log
   97  history > cmds.log
   98  vi cmds.log
   99  Echo $SHELL
  100  echo $SHELL
  101  vi Assignment1
  102  vi Assignment.txt
  103  echo $HOME
  104  vi Assignment1.txt
  105  vi Assignment.txt
  106  vi Assignment1.txt
  107  id
  108  vi Assignment1.txt
  109  mkdir myDir
  110  chmod u-w myDir
  111  cd myDir
  112  ls
  113  ls -1
  114  cd text.txt
  115  cat text.txt
  116  touch abc.txt
  117  cd cs131
  118  cd Assignment1
  119  vi Assignment1.txt
  120  cd myDir2
  121  mkdir myDir2
  122  mkdir myDir3
  123  cd myDir2
  124  touch myFile.txt
  125  mv myFile.txt ../myDir3
  126  ls -1
  127  cd myDir3
  128  cd..
  129  cd ..
  130  cd myDir3
  131  ls -1
  132  cd ..
  133  free -m
  134  cd cs131
  135  cd Assignment1
  136  vi Assignment1.txt
  137  mv ~/counts.txt ~/Worksheet2/i:wq
  138  a=test
  139  vi Assignment1.txt
  140  cd cs131
  141  free -m
  142  cd Assignment1
  143  vi Assignment1.txt
  144  /etc/os-release file
  145  cat /etc/os-release
  146  /etc/os-release file
  147  vi Assignment1.txt
  148  cat /etc/os-release
  149  ls -1
  150  ls -l /etc/os-release
  151  stat -c "%A" /usr/lib/os-release
  152  ls -lL /etc/os-release
  153  vi Assignment1.txt
  154  cd cs131
  155  Assignment1
  156  cd Assignment1
  157  git config --global user.email "gursimran30gcisb@gmail.com"
  158  git config --global user.name "TheTechKnow"
  159  git clone https://github.com/TheTechKnow/cs131.git
  160  git push origin main
  161  eval "$(ssh-agent -s)"
  162  ssh-add ~/.ssh/id_rsa
  163  git push https://github.com/TheTechKnow/cs131.git main
  164  ssh -v git@github.com
  165  git clone https://github.com/TheTechKnow/cs131.git
  166   git clone https://github.com/TheTechKnow/cs131.git
  167  git@github.com:TheTechKnow/cs131.git
  168  .ssh/id_rsa
  169  git remote -v
  170  git branch
  171  git status
  172  git commit
  173  git add
  174  git push origin main
  175  ssh-add
  176  git push origin main
  177  cd ..
  178  cd..
  179  git push origin main
  180  cd ..
  181  git push origin main
  182  cd cs131
  183  git push https://github.com/TheTechKnow/cs131.git main
  184   git push https://github.com/TheTechKnow/cs131.git main
  185  v
  186   git push https://github.com/TheTechKnow/cs131.git main
  187  git push https://github.com/TheTechKnow/cs131.git mai
  188  ls -al ~/.ssh
  189  id_rsa.pub
  190  git config --global user.email "you@example.com"
  191  git config --global user.name "Your Name"
  192  git config --global user.email gursimran30gcisb@gmail.com
  193  git config --global user.name TheTechKnow
  194  cd ~/.ssh && ssh-keygen
  195  cat id_rsa.pub
  196  cd ~/.ssh && ssh-keygen
  197  cat id_rsa.pub
  198  git remote add origin git@github.com:TheTechKnow/cs131.git
  199  cd ..
  200  git remote add origin git@github.com:TheTechKnow/cs131.git
  201  cd cs131
  202  git remote add origin git@github.com:TheTechKnow/cs131.git
  203  git commit -m "The changes"
  204  git push --set-upstream origin master or git push --set-upstream origin main
  205  git status
  206  ls -1
  207  cd cs131
  208  ls -1
  209  cd ..
  210  pwd
  211  ls -l
  212  git add Assignment1
  213  cd Assignment1
  214  ls -l
  215  rm -r cs131
  216  ls
  217  rm -r Assignment.txt
  218  rm Assignment.txt
  219  ls
  220  cd ..
  221  ls
  222  git status
  223  git add Assignment1/Assignment.txt
  224  git status
  225  git add Assignment1/cs131 cmds.log
  226  git status
  227  git commit
  228  git commit -m "Commiting the Assignment1"
  229  git status
  230  git push
  231  git pull
  232  git status
  233  git push
  234  exit
  235  vi cmds.log
  236  cd cs131
  237  cd Assignment1
  238  history > cmds.log
  239  vi cmds.log
  240  cat cmds.log
  241  git remote set-url origin git@github.com:TheTechKnow/cs131.git
  242  git push origin main
  243  cd ..
  244  who
  245  man free
  246  git remote set-url origin git@github.com:TheTechKnow/cs131.git
  247  git clone https://github.com/TheTechKnow/cs131.git
  248  free -m
  249  free
  250  free -b
  251  ls | wc
  252  ls|wc
  253  ls
  254  cd 131
  255  cd cs131
  256  cd
  257  ls -1
  258  cd cs131
  259  ls -1
  260  cd Assignment1
  261  ls -1
  262  cd ..
  263  ls | wc
  264  $ cat * .log |wc
  265  cat * .log |wc
  266  cd cs131
  267  cat * .log |wc
  268  cd ..
  269  who | tee users.lst
  270  who | tee /dev/tty |wc -w
  271  man tee
  272  man paste
  273  ls -l
  274  pwd
  275  ls *.txt
  276  ls? .txt
  277  ls *.txt
  278  ls *assignment
  279  ls ./*.txt
  280  tar tvf tarred_file.tar | grep xxx
  281  tar tvf index.html | grep xxx
  282  man tar
  283  tail -15 index.html
  284  ls -l
  285  sort cs131
  286  wc -1 Assignment1.txt
  287  wc -l Assignment1.txt
  288  wc -l index.html
  289  config
  290  passwd
  291  clear
  292  kl -9
  293  kill -9
  294  kill -l
  295  kill -2
  296  jobs
  297  pwd
  298  fg
  299  bash traps.sh
  300  ps aux
  301  ps aux | chrome
  302  ps aux | safari
  303  ps aux |firefox
  304  ps aux |grep chrome
  305  logout
  306  ulimit -a
  307  jobs
  308  ls -1
  309  cat typescript
  310  cd typrscript
  311  fg
  312  /background
  313  bg
  314  while true; do  echo "waiting for the signal"; sleep 5; done
  315  bash demo.txt
  316  ls -1
  317  bash Assignment1.txt
  318  bash Assignment1.txt &
  319  jobs
  320  ps aux
  321  ps aux|grep Assignment1.txt
  322  logout
  323  mkfifo myPipe1
  324  echo "good morning" > mymyPipe1
  325  echo "good morning" > myPipe1
  326  jobs
  327  ps aux| grep Assignment1.txt
  328  cd cs131
  329  cd Assignment 2
  330  cd Assignment2
  331  cat Assignment2
  332  mkdir Assignment2
  333  cd Assignment2
  334  find /etc -type f > one.txt 2> two.txt
  335  cat Assignment2.txt
  336  cd Assignment.txt
  337  touch Assignment2.txt
  338  vi Assignment2.txt
  339  cat one.txt
  340  cat two.txt
  341  vi Assignment2.txt
  342  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  343  cat Global YouTube Statistics.csv
  344  cd Global YouTube Statistics.csv
  345  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  346  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csvwget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  347  awk -F: '{print $2 ; print $5}' /etc/passwd
  348  cat Assignment1.txt
  349  {print $5
  350  awk -F: '-f Assignment1.txt' /etc/passwd
  351  awk 'BEGIN {print "the name:"} /[gG]ursimran/ {print}' cs131
  352  awk 'BEGIN {print "the name:"} /[iI]input/ {print}' cs131
  353  awk 'BEGIN {print "the name:"} /[iI]input/ {print}' Assignment1.txt
  354  awk 'BEGIN {print "the name:"} /[cC]ommand/ {print}' Assignment1.txt
  355  awk 'BEGIN {print "the name:"} /[fF]ile/ {print}' Assignment1.txt
  356  awk 'BEGIN {print "the name:"} /[fF]ile/ {print}' Assignment2.txt
  357  awk 'BEGIN {print "lc=0"}// {lc++} END {print lc}' Assignment2.txt
  358  awk 'BEGIN {print "lc=0"}// {lc++} END {print lc}' spotify-2023.csv
  359  cd cs131
  360  ls -l
  361  awk 'BEGIN {print "lc=0"}// {lc++} END {print lc}' Assignment1.txt
  362  cd..
  363  cd ..
  364  cd /path/to/directory/containing/spotify-2023.csv
  365  awk 'BEGIN {print "lc=0"}// {lc++} END {print lc}' spotify-2023.csv
  366  ls -l
  367  awk 'BEGIN {print "lc=0"}// {lc++} END {print lc}' index.html
  368  awk 'BEGIN {print "lc=0"}// {lc++} END {print lc}' cmds.log
  369  awk 'BEGIN {print "lc=0"}// {lc++} END {print lc}' Global YouTube Statistics.csv
  370  awk 'BEGIN {print "lc=0"}// {lc++} END {print lc}' 'Global YouTube Statistics.csv'
  371  awk 'BEGIN {print "lc=0"}// {lc++} END {print lc}' typescript
  372  cat typesript
  373  cat typescript
  374  awk 'BEGIN {print "lc=0"}// {lc++} END {print lc}' users.lst
  375  cat users.lst 
  376  history > cmds.log
  377  vi cmds.log
  378  quit
  379  clear
  380  :wq'
  381  cut -d ',' -f3,4 "Global YouTube Statistics.csv" | tail -n +2 | sort -t ',' -k2,2 -k1,1 | uniq -c | sort -nr | head -n 3
  382  cut -d ',' -f6 "Global YouTube Statistics.csv" | tail -n +2 > years.txt
  383  cut -d ',' -f7 "Global YouTube Statistics.csv" | tail -n +2 > months.txt
  384  paste -d ',' years.txt months.txt > year_month.txt
  385  sort -t ',' -k2,2 -k1,1 year_month.txt | uniq -c > counts.txt
  386  sort -nr counts.txt > sorted_counts.txt
  387  head -n 3 sorted_counts.txt > top_3_combinations.txt
  388  cat top_3_combinations.txt
  389  ps -u gursimransp24
  390  ps -u gursimransp24 > Assignment2.txt
  391  cat Assignment2.txt
  392  cd cs131
  393  cd Assignment2
  394  ps -u gursimransp24
  395  ps -u gursimransp24 > Assignment2.txt
  396  cat Assignment2.txt
  397  vi Assignment2.txt
  398  ls -l
  399  cd ..
  400  cd Assignment2
  401  cdms.log
  402  cat cmds.log
  403  cd cmds.log
  404  cd ..
  405  cmds.log
  406  cat cmds.log
  407  ls -l
  408  cd ..
  409  ls -l
  410  cat cmds.log
  411  :wq
  412  cd cs131
  413  cd Assignment2
  414  cd Assignment2.txt
  415  cat Assignment2.txt 
  416  find /etc -type f > one.txt 2> two.txt
  417  cat one.txt
  418  cat two.txt
  419  vi Assignment2.txt
  420  vi file.txt 
  421  vi Assignment2.txt
  422  ps -u gursimransp24
  423  vi Assignment2.txt
  424  ps -u gursimransp24
  425  ps -u gursimransp24>Assignment2.txt
  426  vi Assignment2.txt
  427  u
  428  vi Assignment2.txt
  429  ps -u gursimransp24
  430  vi Assignment2.txt
  431  PID 1
  432  ps -p 1
  433  /sbin/init
  434  cd ..
  435   history > cmds.log
  436  history > cmds.log
  437  cd cs131
  438  cd Assignment2
  439  cat Assignment2.txt
  440  cd ..
  441  vi file.txt 
  442  rm -r file.txt
  443  ps -u gursimransp24
  444  ps -u gursimransp24> Assignment2.txt
  445  ps -u gursimransp24> file.txt
  446  vi Assignment2.txt
  447  ps -u gursimransp24> cs131>Assignment2> Assignment2.txt
  448  vi file.txt 
  449  cat cmds.log
  450  clear
  451  cd cs131
  452  cd Assignment2.txt
  453  cd Assignment2
  454  vi Assignment2.txt
  455  ps aux | grep [i]nit
  456  pgrep -x init
  457  ps aux|grep "1"
  458  ps -p 1
  459  systemd
  460  ps -pid 1
  461  ps --pid 1
  462  vi Assignment.txt
  463  vi Assignment2.txt
  464  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  465  cat ‘Global YouTube Statistics.csv.3’
  466  gursimransp24@sjsu Assignment2]$ cat ‘Global YouTube Statistics.csv.3’
  467  cat: ‘Global: No such file or directory
  468  cat: YouTube: No such file or directory
  469  cat: Statistics.csv.3’: No such file or directory
  470  [gursimransp24@sjsu Assignment2]$ 
  471  gursimransp24@sjsu Assignment2]$ cat ‘Global YouTube Statistics.csv.3’
  472  cat: ‘Global: No such file or directory
  473  cat: YouTube: No such file or directory
  474  cat: Statistics.csv.3’: No such file or directory
  475  [gursimransp24@sjsu Assignment2]$ 
  476  gursimransp24@sjsu Assignment2]$ cat ‘Global YouTube Statistics.csv’
  477  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv\
  478  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  479  ls -1
  480  cat 'Global YouTube Statistics.csv'
  481  cut -d ',' -f22,23 "Global YouTube Statistics.csv"
  482  cut -d ',' -f20,21 "Global YouTube Statistics.csv"
  483  cut -d ',' -f21,20 "Global YouTube Statistics.csv"
  484  tail -n +2
  485  cut -d ',' -f20,21 "Global YouTube Statistics.csv"
  486  cut -d ',' -f20,21 "Global YouTube Statistics.csv" | tail -n +2 | sort | uniq -c | sort -nr | head -n 3
  487  awk -F ',' 'NR > 1 {count[$20","$21]++} END {for (combo in count) print count[combo], combo}' "Global YouTube Statistics.csv" | sort -nr | head -n 3
  488  vi Assignment2.txt
  489  history > cmds.log
  490  cat cmds.log
  491  git add Assignment2
  492  git clone https://github.com/TheTechKnow/cs131.git
  493  git add Assignment2
  494  git status
  495  cd ..
  496  git add Assignment2
  497  git status
  498  git add Assignment2/Assignment2.txt
  499  git add Assignment1/cs131 cmds.log
  500  git add Assignment2/cs131 cmds.log
  501  git commit -m "Commiting the Assignment2"
  502  git status
  503  git push
  504  git pull
  505  git status
  506  git push
  507  cd cs131
  508  ls -l
  509  cd Assignment2
  510  cs -l
  511  ls -l
  512  mv 'Global YouTube Statistics.csv.5'>cs131
  513  cd ..
  514  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  515  cat ‘Global YouTube Statistics.csv’
  516  awk 'BEGIN {FS=":"} {if ($7== "/usr/sbin/nologin") print $0}' /etc/passwd
  517  awk 'BEGIN {FS=":"} {print $7}' /etc/passwd
  518  cat awkscr_if
  519  cd awk
  520  /etc/passwd
  521  clear
  522  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  523  ls -l
  524  cd cs131
  525  cd Worksheet3
  526  mkdir Worksheet3
  527  cd Worksheet3
  528  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  529  cat ‘Global YouTube Statistics.csv’
  530  cat "Global YouTube Statistics.csv"
  531  grep -E 'United States|United Kingdom|India' Youtube2023Dataset.csv | sort -t ',' -k 7 -n -r > highest_monthly_earners.txt
  532  grep -E 'United States|United Kingdom|India' Global YouTube Statistics.csv | sort -t ',' -k 7 -n -r > highest_monthly_earners.txt
  533  grep -E 'United States|United Kingdom|India' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r > highest_monthly_earners.txt
  534  'grep -E 'United States|United Kingdom|India' | cut -d ',' -f16 "Global YouTube Statistics.csv" | tail -n +2 | sort | uniq -c | sort -nr | head -n 3
  535  '
  536  grep -E 'United States|United Kingdom|India' | cut -d ',' -f16 "Global YouTube Statistics.csv" | tail -n +2 | sort | uniq -c | sort -nr | head -n 3
  537  grep -E 'United States|United Kingdom|India'"Global YouTube Statistics.csv"| tail -n +2 | sort | uniq -c | sort -nr | head -n 3
  538  grep -E 'United States|United Kingdom|India' "Global YouTube Statistics.csv" | tail -n +2 | sort | uniq -c | sort -nr | head -n 3
  539  grep -E 'United States|United Kingdom|India' Global YouTube Statistics.csv | sort -t ',' -k 7 -n -r | awk -F ',' '{if ($1 == "United States" && NR==1) print "Highest earner from United States:", $3, "with earnings $", $7} {if ($1 == "United Kingdom" && NR==1) print "Highest earner from United Kingdom:", $3, "with earnings $", $7} {if ($1 == "India" && NR==1) print "Highest earner from India:", $3, "with earnings $", $7}'
  540  cd cs131
  541  cd Worksheet3
  542  grep -E 'United States|United Kingdom|India' Global YouTube Statistics.csv | sort -t ',' -k 7 -n -r | awk -F ',' '{if ($1 == "United States" && NR==1) print "Highest earner from United States:", $3, "with earnings $", $7} {if ($1 == "United Kingdom" && NR==1) print "Highest earner from United Kingdom:", $3, "with earnings $", $7} {if ($1 == "India" && NR==1) print "Highest earner from India:", $3, "with earnings $", $7}'
  543  grep -E 'United States|United Kingdom|India' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | awk -F ',' '{if ($1 == "United States" && NR==1) print "Highest earner from United States:", $3, "with earnings $", $7} {if ($1 == "United Kingdom" && NR==1) print "Highest earner from United Kingdom:", $3, "with earnings $", $7} {if ($1 == "India" && NR==1) print "Highest earner from India:", $3, "with earnings $", $7}'
  544  grep -E 'United States|United Kingdom|India' Youtube2023Dataset.csv > filtered_countries.csv
  545  grep -E 'United States|United Kingdom|India' Global YouTube Statistics.csv.csv > filtered_countries.csv
  546  ls -l
  547  grep -E 'United States|United Kingdom|India' 'Global YouTube Statistics.csv' > filtered_countries.csv
  548  sort -t ',' -k 7 -n -r filtered_countries.csv > sorted_earnings.csv
  549  for country in "United States" "United Kingdom" "India"; do     grep "$country" sorted_earnings.csv | head -n 1 > highest_earner_$country.txt; done
  550  cat country.txt
  551  ls -l
  552  cat highest_earner_India.txt
  553  cat highest_monthly_earners.txt
  554  {     grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | head -n 1;     grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | head -n 1;     grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | head -n 1;      grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 5 -n -r | head -n 1;     grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 5 -n -r | head -n 1;     grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 5 -n -r | head -n 1; } > ws3.txt
  555  cat ws3.txt
  556  {     grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | head -n 1 | cut -d ',' -f 8,7;      grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | head -n 1 | cut -d ',' -f 8,7;      grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | head -n 1 | cut -d ',' -f 8,7;      grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 5 -n -r | head -n 1 | cut -d ',' -f 10,5;      grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 5 -n -r | head -n 1 | cut -d ',' -f 10,5;      grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 5 -n -r | head -n 1 | cut -d ',' -f 10,5; } >> combined_results.txt
  557  combined_results.txt
  558  cat combined_results.txt 
  559  {     grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 13 -n -r | head -n 1 | cut -d ',' -f 8,13;      grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 13 -n -r | head -n 1 | cut -d ',' -f 8,13;      grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 13 -n -r | head -n 1 | cut -d ',' -f 8,13;      grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3;      grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3;      grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3; } > combined_results.txt
  560  cat combined_results.txt 
  561  {     grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15;      grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15;      grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15;      grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3;      grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3;      grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3; } > combined_results.txt
  562  cat combined_results.txt 
  563  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15 > combined_results.txt
  564  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15 >> combined_results.txt
  565  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15 >> combined_results.txt
  566  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  567  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  568  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  569  cat combined_results.txt 
  570  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15 > combined_results.txt
  571  # Extract country name and earnings for United Kingdom
  572  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15 >> combined_results.txt
  573  # Extract country name and earnings for India
  574  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15 >> combined_results.txt
  575  # Task 2: Finding the highest subscribed channel from three different categories
  576  # Extract category, YouTube, and subscribers for Sports
  577  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  578  # Extract category and subscribers for Education
  579  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  580  # Extract category and subscribers for Entertainment
  581  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  582  cat combined_results.txt 
  583  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 18 -n -r | head -n 1 | cut -d ',' -f 8,18 > combined_results.txt
  584  # Extract country name and earnings for United Kingdom
  585  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 18 -n -r | head -n 1 | cut -d ',' -f 8,18 >> combined_results.txt
  586  # Extract country name and earnings for India
  587  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 18 -n -r | head -n 1 | cut -d ',' -f 8,18 >> combined_results.txt
  588  # Task 2: Finding the highest subscribed channel from three different categories
  589  # Extract category, YouTube, and subscribers for Sports
  590  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  591  # Extract category and subscribers for Education
  592  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  593  # Extract category and subscribers for Entertainment
  594  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  595  cat combined_results.txt 
  596  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 > combined_results.txt
  597  # Extract country name and earnings for United Kingdom
  598  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  599  # Extract country name and earnings for India
  600  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  601  # Task 2: Finding the highest subscribed channel from three different categories
  602  # Extract category, YouTube, and subscribers for Sports
  603  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  604  # Extract category and subscribers for Education
  605  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  606  # Extract category and subscribers for Entertainment
  607  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  608  cat combined_results.txt 
  609  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 > combined_results.txt
  610  # Extract country name and earnings for United Kingdom
  611  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  612  # Extract country name and earnings for India
  613  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  614  # Task 2: Finding the highest subscribed channel from three different categories
  615  # Extract category, YouTube, and subscribers for Sports
  616  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  617  # Extract category, YouTube, and subscribers for Education
  618  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  619  # Extract category, YouTube, and subscribers for Entertainment
  620  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  621  cat combined_results.txt 
  622  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 > combined_results.txt
  623  # Extract country name and earnings for United Kingdom
  624  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  625  # Extract country name and earnings for India
  626  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  627  # Task 2: Finding the highest subscribed channel from three different categories
  628  # Extract category, YouTube, and subscribers for Sports
  629  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  630  # Extract category, YouTube, and subscribers for Education
  631  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  632  # Extract category, YouTube, and subscribers for Entertainment
  633  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  634  cat combined_results.txt 
  635  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 > combined_results.txt
  636  # Extract country name and earnings for United Kingdom
  637  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  638  # Extract country name and earnings for India
  639  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  640  # Task 2: Finding the highest subscribed channel from three different categories
  641  # Extract category, YouTube, and subscribers for Sports
  642  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  643  # Extract category, YouTube, and subscribers for Education
  644  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  645  # Extract category, YouTube, and subscribers for Entertainment
  646  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  647  cat combined_results.txt 
  648  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 > combined_results.txt
  649  # Extract country name and earnings for United Kingdom
  650  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  651  # Extract country name and earnings for India
  652  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  653  # Task 2: Finding the highest subscribed channel from three different categories
  654  # Extract category, YouTube, and subscribers for Sports
  655  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  656  # Extract category, YouTube, and subscribers for Education
  657  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  658  # Extract category, YouTube, and subscribers for Entertainment
  659  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  660  cat combined_results.txt 
  661  awk -F ',' '$5 == "Education" && $3 > max {max = $3; line = $5 "," $2 "," $3} END {print line}' "Global YouTube Statistics.csv" >> combined_results.txt
  662  cat combined_results.txt 
  663  awk -F ',' '$5 == "Sports" && $3 > max {max = $3; line = $5 "," $2 "," $3} END {print line}' "Global YouTube Statistics.csv" >> combined_results.txt
  664  awk -F ',' '$5 == "Entertainment" && $3 > max {max = $3; line = $5 "," $2 "," $3} END {print line}' "Global YouTube Statistics.csv" >> combined_results.txt
  665  cat combined_results.txt 
  666  ws3.txt
  667  ls -l
  668  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 > ws3.txt
  669  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> ws3.txt
  670  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> ws3.txt
  671  awk -F ',' '$5 == "Sports" && $3 > max {max = $3; line = $5 "," $2 "," $3} END {print line}' "Global YouTube Statistics.csv" >> ws3.txt
  672  awk -F ',' '$5 == "Education" && $3 > max {max = $3; line = $5 "," $2 "," $3} END {print line}' "Global YouTube Statistics.csv" >> ws3.txt
  673  awk -F ',' '$5 == "Entertainment" && $3 > max {max = $3; line = $5 "," $2 "," $3} END {print line}' "Global YouTube Statistics.csv" >> ws3.txt
  674  cat ws3.txt 
  675  rm combined_results.txt
  676  rm filtered_countries.csv
  677  rm highest_earner_India.txt
  678  rm highest_monthly_earners.txt
  679  rm sorted_earnings.csv
  680  ls -l
  681  vi ws3.txt 
  682  history > cmds.log
  683  ls -l
  684  git add 
  685  git add Worksheet3
  686  cd ..
  687  git add Worksheet3
  688  git commit -m "commiting the Worksheet 3"
  689  git push
  690  git status
  691  git pull
  692  git push
  693  echo "Hello, I'm <name>." | sed "s|<name>|$HOME|"
  694  echo "Hello, I'm <name>." | sed "s/<name>/$HOME/"
  695  echo "Hello, I'm <name>." | sed "s|<name>|$HOME|"
  696  awk 'BEGIN {print 'howdy, folks'}'
  697  awk "BEGIN {print 'howdy, folks'}"
  698  awk "BEGIN {print Hi}'
  699  awk 'BEGIN {print "howdy,\n folks"}'
  700  awk 'BEGIN {print "howdy, folks"}'
  701  awk 'BEGIN {print "howdy, $folks"}'
  702  awk -v PWD=$PWD "BEGIN {print PWD}"
  703  last
  704  /dev/pts
  705  #!/bin/bash
  706  hg
  707  vi Scriptfilename
  708  #!/bin/bash
  709  vi Scriptfilename.sh
  710  #!/bin/bash
  711  ~/.bash_profile
  712  pwd
  713  ls -la ~/.bash_profile
  714  vi ~/.bash_profile
  715  alias l='ls -ltr'
  716  alias w='ls -l | wc -l'
  717  source ~/.bash_profile
  718  l
  719  w
  720  mkdir Worksheet4/Subscribers
  721  mkdir -p Worksheet4/Subscribers
  722  cat 'Global YouTube Statistics.csv'
  723  grep "United States" YouTubers.csv | cut -d ',' -f 3 > Worksheet4/Subscribers/United_States.txt
  724  grep "United States" 'Global YouTube Statistics.csv' | cut -d ',' -f 4 > Worksheet4/Subscribers/United_States.txt
  725  grep "United States" 'Global YouTube Statistics.csv' | cut -d ',' -f 4 > Worksheet4/Subscribers/India.txt
  726  cat United_states.txt
  727  vi United_states
  728  cat United_States.txt
  729  grep "United States" 'Global YouTube Statistics.csv' | cut -d ',' -f 3 > Worksheet4/Subscribers/United_States.txt
  730  grep "India" 'Global YouTube Statistics.csv' | cut -d ',' -f 3 > Worksheet4/Subscribers/India.txt
  731  cat Worksheet4/Subscribers/United_States.txt
  732  cat Worksheet4/Subscribers/India.txt
  733  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' >> Worksheet4/ws4_means.txt
  734  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./; s/$/\/NR/' | bc -lq >> Worksheet4/ws4_means.txt
  735  echo "$(paste -sd+ Worksheet4/Subscribers/United_States.txt)" | bc -lq | sed 's/^\./0./' | awk '{print $0 / NR}' >> Worksheet4/ws4_means.txt
  736  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' > Worksheet4/Subscribers/US_mean.txt
  737  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' > temp_us_mean.txt
  738  total_us=$(sed 's/\n/+/g' temp_us_mean.txt)
  739  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' > temp_us_mean.txt
  740  total_us=$(sed 's/\n/+/g' temp_us_mean.txt)paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' > temp_us_mean.txt
  741  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' > temp_us_mean.txt
  742  total_us=$(paste -sd+ Worksheet4/Subscribers/United_States.txt)
  743  count_us=$(wc -l < Worksheet4/Subscribers/United_States.txt)
  744  echo "$total_us/$count_us" | bc -lq | sed 's/^\./0./' >> Worksheet4/ws4_means.txt
  745  echo "scale=2; $total_us / $count_us" | bc | sed 's/^\./0./' >> Worksheet4/ws4_means.txt
  746  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' > us_mean.txt
  747  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq > Worksheet4/Subscribers/US_mean.txt
  748  vi greetings.txt
  749  sed -i 's/Hello/Hi/g' greetings.txt
  750  cat greetings.txt 
  751  sed -i '/Doe/d' greetings.txt
  752  cat greetings.txt 
  753  sed -i 's/$/ (edited)/' greetings.txt
  754  cat greetings.txt 
  755  sed -i '/^Hello,.*Michael Johnson/s/Michael Johnson/Mike Johnson/' greetings.txt
  756  cat greetings.txt 
  757  ls -1
  758  cd cs131
  759  cd Worksheet4
  760  mkdir Worksheet4
  761  cd ..
  762  cd .
  763  cd..
  764  ls -1
  765  cd Worksheet4
  766  ls -l
  767  cd Subscribers/
  768  ls -l
  769  rm US_mean.txt 
  770  ls -l
  771  cd ..
  772  pwd
  773  cd..
  774  cd ..
  775  pwd
  776  mv greetings.txt Worksheet4/
  777  cd Worksheet4
  778  ls -l
  779  total_us=$(paste -sd+ Worksheet4/Subscribers/United_States.txt)
  780  cd ..
  781  total_us=$(paste -sd+ Worksheet4/Subscribers/United_States.txt)
  782  count_us=$(wc -l < Worksheet4/Subscribers/United_States.txt)
  783  echo "scale=2; $total_us / $count_us" | bc -lq > Worksheet4/ws4_means.txt
  784  echo "$total_us / $count_us" | awk '{ printf "%.2f\n", $1 }' > Worksheet4/ws4_means.txt
  785  cat ws4_means.txt
  786  cd Worksheet4
  787  cat ws4_means.txt
  788  total_India=$(paste -sd+ Worksheet4/Subscribers/India.txt)
  789  cd ..
  790  total_India=$(paste -sd+ Worksheet4/Subscribers/India.txt)
  791  echo "scale=2; $total_India / $count_India" | bc -lq > Worksheet4/ws4_means.txt
  792  count_india=$(wc -l < Worksheet4/Subscribers/India.txt)
  793  echo "$total_india / $count_india" | awk '{ printf "%.2f\n", $1 }' >> Worksheet4/ws4_means.txt
  794  cd Worksheet4
  795  cat ws4_means.txt 
  796  total_us=$(paste -sd+ Worksheet4/Subscribers/United_States.txt)
  797  cd ..
  798  total_us=$(paste -sd+ Worksheet4/Subscribers/United_States.txt)
  799  count_india=$(wtotal_india=$(paste -sd+ Worksheet4/c -l < Worksheet4/Subscribers/Un.txt)
  800  echo "$total_us / $count_us" | awk '{ printf "%.2f\n", $1 }' > Worksheet4/ws4_means.txt
  801  total_india=$(paste -sd+ Worksheet4/Subscribers/United_States.txt)
  802  total_india=$(paste -sd+ Worksheet4/Subscribers/India.txt)
  803  count_india=$(wc -l < Worksheet4/Subscribers/India.txt)
  804  echo "$total_india / $count_india" | awk '{ printf "%.2f\n", $1 }' >> Worksheet4/ws4_means.txt
  805  cd Worksheet4
  806  cat ws4_means.txt 
  807  ls -l
  808  clear
  809  script ws4.txt
  810  cat ws4.txt
  811  ls -l
  812  cd Worksheet4
  813  ls -l
  814  mv ws4.txt Worksheet4/
  815  cd ..
  816  mv ws4.txt Worksheet4/
  817  cd Worksheet4
  818  ls -l
  819  cd ..
  820  cd cs131
  821  ls -l
  822  cd Worksheet4
  823  ls -l
  824  cd ..
  825  rm Worksheet4
  826  rmdir Worksheet4
  827  ls -l
  828  cd ..
  829  mv Worksheet4 cs131
  830  cd cs131
  831  ls -l
  832  cd Worksheet4
  833  ls -l
  834  cd ..
  835  git add Worksheet4
  836  git status
  837  git commit" add the worksheet4"
  838  git commit -m "commiting the worksheet4"
  839  git status
  840  git push
  841  git pull
  842  git push
  843  sed 's/Pineapple/Feta/' tops.txt 
  844  touch tops.txt
  845  vi tops.txt
  846  sed 's/Pineapple/Feta/' tops.txt 
  847  sed 's/Pineapple/Feta/g' tops.txt
  848  sed 's.Pineapple.Feta.' tops.txt
  849  vi tops.txt
  850  sed 's.Pineapple.Feta.' tops.txt
  851  sed 's|Pineapple|Feta|' tops.txt 
  852   sed ‘/Pineapples/ d’ tops.txt
  853  sed ‘/Pineapples/ d’ tops.txt
  854   sed '3 d' tops.txt
  855  sed 's/Pineapples/Half &/' tops.txt
  856  sed 'Pq' tops.txt
  857  sed '3q' tops.txt
  858  touch *
  859  ls -l
  860  touch *.txt
  861  ls -l
  862  vi *.txt
  863  ls -l
  864   rm 
  865   rm *.txt
  866  touch text.txt
  867  ls -l
  868  cd ..
  869  ls -l
  870  cd gursimranp24
  871  cd ..
  872  home
  873  ~
  874  echo home
  875  awk '/Pineapples/' tops.txt
  876  cat tops.txt
  877  ls -l
  878  cd cs131
  879  ls -l
  880  cd ..
  881  vi text.txt
  882  awk '/Pineapples/' text.txt
  883  cat
  884  cat text.txt
  885  vi text.txt 
  886  awk '/Pineapples/' text.txt
  887  awk -F: '{print $1}' /etc/passwd
  888  awk -F: '{print $5 ; print $6; print$7}'
  889  awk -F: '{print $5 ; print $6; print$7}' /etc/passwd
  890  awk '/Pineapples/ { print }' text.txt
  891  awk 'BEGIN {lc=0} // {lc++} END {print lc}' text.txt
  892  cat text.txt
  893  awk 'BEGIN {i=1} i<4 {print; i++}' text.txt
  894  awk 'BEGIN {FS=","; OFS="\t"} {print $1, $2}' text.txt
  895  awk 'END { print "Total number of records: " NR }' text.txt
  896  awk '{ print "Line " NR ": " $0 }' text.txt
  897  awk -v user=jyotika -f awkscr_option-v /etc/passwd
  898  awk 'BEGIN {FS=":"} {print $1, " uses ", $7}' /etc/passwd
  899  awk 'BEGIN {FS=":"} {if ($7 == "/usr/sbin/nologin") print $0}'
  900  awk 'BEGIN {FS=":"} {if ($7 == "/usr/sbin/nologin") print $0}' /etc/passwd
  901  awk ‘BEGIN {print int(57.43)}’
  902  awk ‘BEGIN {print sqrt(25)}’
  903  awk '{ if (length ($0)) print }' text.txt
  904  awk -F : '{ if(index($0, "bash")) print}' /etc/passwd
  905  $ awk -F : '{ print tolower ($5)}' /etc/passwd
  906  awk -F : '{ print toupper ($5)}' /etc/passwd
  907  `
  908  awk -F : '{ if (match ($0, "bash")) print $1 " uses "
  909  $7}' /etc/passwd
  910  awk '{split ($0, all, ":"); print all[1], " is known
  911  as " all[5]}' /etc/passwd
  912  awk '{split ($0, all, ":"); print all[1], " is known
  913  as " all[5]}' /etc/passwd
  914  awk '{split ($0, all, ":"); print all[1], " is known
  915  as " all[5]}' /etc/passwd
  916  awk '{split ($0, all, ":"); print all[1], "is known as" all[5]}' /etc/passwd
  917  echo "Hello, I'm <name>." | sed "s/<name>/$HOME/"
  918  echo "Hello, I'm <name>." | sed "s|<name>|$HOME|"
  919  cat pos.sh
  920  touch pos.sh
  921  cat pos.sh
  922  cd pos.sh
  923  vi pos.sh 
  924  ls
  925  cat pos.sh
  926  bash pos.sh Coffee
  927  bash pos.sh 
  928  *
  929  cs 131`
  930  cd cs 131
  931  cd cs131
  932  *
  933  $*
  934  $$
  935  cd ..
  936  $*
  937  $$
  938  bash $$
  939  echo $*
  940  echo $$
  941  echo $?
  942  read A B 
  943  echo $A
  944  read A B C
  945  #! /bin/bash
  946  echo "who am I talking to?"
  947  read user_name
  948  echo "Hello $user_name"
  949  echo "with $user_name"
  950  echo $?
  951  ls
  952  touch variables.sh
  953  vi variables.sh 
  954  echo $count
  955  bash variables.sh 
  956  $PATH
  957  a=10
  958  echo $a
  959  touch local variable
  960  rm local variable
  961  touch local_variable.sh
  962  cat local_variable.sh 
  963  vi local_variable.sh 
  964  bash local_variable.sh 
  965  vi local_variable.sh 
  966  bash local_variable.sh 
  967  echo $FAV_CHARACTER
  968  ls
  969  mkdir Scripts
  970  mv local_variable.sh Scripts
  971  ls
  972  mv pos.sh Scripts
  973  mv variables.sh Scripts
  974  cd Scripts
  975  ls
  976   a=1+2
  977  echo $a
  978  a=`expr 1+2`
  979  echo $a
  980  a = `expr 1 + 2`
  981  a = `$expr 1 + 2`
  982  a=`expr 1 + 2`
  983  echo $a
  984  touch areaOfRectangle
  985  vi areaOfRectangle 
  986  car areaOfRectangle 
  987  cat areaOfRectangle 
  988  ./areaOfRectangle
  989  ls
  990  ls areaOfRectangle 
  991  bash 
  992  ls -l
  993  ./areaOfRectangle
  994  vi areaOfRectangle 
  995  ./areaOfRectangle
  996  cd cs131
  997  mkdir Assignment3
  998  cd Assignment3
  999  man last
 1000  cat last
 1001  last
 1002  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/last.fake
 1003  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/passwd.fake
 1004  cat last.fake
 1005  wc -l last.fake
 1006  grep 'sp24' last.fake > lastsp24.fake
 1007  cat lastsp24.fake 
 1008  wc -l lastsp24.fake 
 1009  wc -l last.fake
 1010  sed -n '/sp24/!p' last.fake | wc -l
 1011  grep 'Sun' lastsp24.fake
 1012  awk '{print $1}' lastsp24.fake
 1013  awk '{print $1}' lastsp24.fake | sort | uniq
 1014  awk '{print $1}' lastsp24.fake | wc -l
 1015  awk '{print $1}' lastsp24.fake | sort | uniq | wc -l
 1016  grep 'Sun' lastsp24.fake | awk '{print $1}' lastsp24.fake
 1017  grep 'Sun' lastsp24.fake | awk '{print $1}'
 1018  grep 'Sun' lastsp24.fake | awk '{print $1}' | sort | uniq
 1019  awk '/Sun/ {print $1} END {print "Kudos to these people for putting in the work"}' lastsp24.fake | sort | uniq
 1020  awk '/Sun/ {print $1} END {if (NR>0) print "Kudos to these people for putting in the work"}' lastsp24.fake | sort | uniq
 1021  awk 'BEGIN {print "The list of people who worked on Sunday are:"} /Sun/ {print $1} END {if (NR>0) print "Kudos to these people for putting in the work"}' lastsp24.fake | sort | uniq
 1022  awk 'BEGIN {print "The list of people who worked on Sunday are:"} /Sun/ {users[$1]} END {for (user in users) print user; if (length(users) > 0) print "Kudos to these people for putting in the work"}' lastsp24.fake | sort | uniq
 1023  awk 'BEGIN {print "The list of people who worked on Sunday are:"} /Sun/ {print $1} END {if (NR>0) print "Kudos to these people for putting in the work"}' lastsp24.fake
 1024  awk 'BEGIN {print "The list of people who worked on Sunday are:"} /Sun/ {print $1} END {if (NR>0) print "Kudos to these people for putting in the work"}' lastsp24.fake|uniq
 1025  touch Assignment3.txt
 1026  vi Assignment3.txt 
 1027  grep 'Sun' lastsp24.fake | awk '{print $1}' | sort | uniq > last1.fake
 1028  awk 'BEGIN {print "The list of people who worked on Sunday are:"} /Sun/ {print $1} END {if (NR>0) print "Kudos to these people for putting in the work"}' last1.fake 
 1029  vi Assignment3.txt 
 1030  awk '{split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1}' lastsp24.fake | sort | uniq
 1031  vi Assignment3.txt 
 1032  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq
 1033  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | uniq
 1034  awk '{split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1}' lastsp24.fake | sort | uniq |wc -l
 1035  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | uniq | wc -l
 1036  awk 'BEGIN {print "The list of people who worked on Sunday are:"} /Sun/ {print $1} END {if (NR>0) print "Kudos to these people for putting in the work"}' lastsp24.fake|uniq
 1037  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq 
 1038  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq
 1039  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort -u
 1040  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq
 1041  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) users[$1]} END {for (user in users) print user; if (length(users) > 0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq
 1042  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | uniq
 1043  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | uniq |wc -l
 1044  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | uniq |sort
 1045  awk 'BEGIN {print "Night Owls List:"} '{split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1}'END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq
 1046  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq
 1047  awk '{split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1}' lastsp24.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print} END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}'
 1048  vi Assignment3.txt 
 1049  awk '{split($5, a, ":"); if ((a[1] >= 5) && (a[1] <= 9)) print $1}' lastsp24.fake | sort | uniq | awk 'BEGIN {print "Early Birds List:"} {print} END {if (NR>0) print "Early Birds are dope. Please ensure you get enough sleep though."}'
 1050  vi Assignment3.txt 
 1051  awk '/^t/' lastsp24.fake
 1052  awk '/^t/ {print $1}' lastsp24.fake
 1053  awk '/^t/ {print $1}' lastsp24.fake | sort | uniq
 1054  vi Assignment3.txt 
 1055  cat passwd.fake 
 1056  awk -F: '$1 ~ /^a/ && $3 % 2 == 0 {print $1}' passwd.fake
 1057  vi Assignment3.txt 
 1058  sed 's/[a-zA-Z0-9[:space:]]//g' passwd.fake | sed '/^$/d' | sort -u
 1059  sed '/[[:alnum:][:space:]]/d' passwd.fake | sort -u
 1060  sed '/[a-zA-Z0-9 ]/d' passwd.fake | sed '/^$/d' | sort -u
 1061  sed 's/[a-zA-Z0-9[:space:]]//g' passwd.fake | sed '/^$/d' | sort -u
 1062  vi Assignment3.txt 
 1063  ls -l
 1064  ls
 1065  history >> cmds.log
