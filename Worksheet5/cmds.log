   88  awk 'BEGIN {print "lc=0"}// {lc++} END {print lc}' typescript
   89  cat typesript
   90  cat typescript
   91  awk 'BEGIN {print "lc=0"}// {lc++} END {print lc}' users.lst
   92  cat users.lst 
   93  history > cmds.log
   94  vi cmds.log
   95  quit
   96  clear
   97  :wq'
   98  cut -d ',' -f3,4 "Global YouTube Statistics.csv" | tail -n +2 | sort -t ',' -k2,2 -k1,1 | uniq -c | sort -nr | head -n 3
   99  cut -d ',' -f6 "Global YouTube Statistics.csv" | tail -n +2 > years.txt
  100  cut -d ',' -f7 "Global YouTube Statistics.csv" | tail -n +2 > months.txt
  101  paste -d ',' years.txt months.txt > year_month.txt
  102  sort -t ',' -k2,2 -k1,1 year_month.txt | uniq -c > counts.txt
  103  sort -nr counts.txt > sorted_counts.txt
  104  head -n 3 sorted_counts.txt > top_3_combinations.txt
  105  cat top_3_combinations.txt
  106  ps -u gursimransp24
  107  ps -u gursimransp24 > Assignment2.txt
  108  cat Assignment2.txt
  109  cd cs131
  110  cd Assignment2
  111  ps -u gursimransp24
  112  ps -u gursimransp24 > Assignment2.txt
  113  cat Assignment2.txt
  114  vi Assignment2.txt
  115  ls -l
  116  cd ..
  117  cd Assignment2
  118  cdms.log
  119  cat cmds.log
  120  cd cmds.log
  121  cd ..
  122  cmds.log
  123  cat cmds.log
  124  ls -l
  125  cd ..
  126  ls -l
  127  cat cmds.log
  128  :wq
  129  cd cs131
  130  cd Assignment2
  131  cd Assignment2.txt
  132  cat Assignment2.txt 
  133  find /etc -type f > one.txt 2> two.txt
  134  cat one.txt
  135  cat two.txt
  136  vi Assignment2.txt
  137  vi file.txt 
  138  vi Assignment2.txt
  139  ps -u gursimransp24
  140  vi Assignment2.txt
  141  ps -u gursimransp24
  142  ps -u gursimransp24>Assignment2.txt
  143  vi Assignment2.txt
  144  u
  145  vi Assignment2.txt
  146  ps -u gursimransp24
  147  vi Assignment2.txt
  148  PID 1
  149  ps -p 1
  150  /sbin/init
  151  cd ..
  152   history > cmds.log
  153  history > cmds.log
  154  cd cs131
  155  cd Assignment2
  156  cat Assignment2.txt
  157  cd ..
  158  vi file.txt 
  159  rm -r file.txt
  160  ps -u gursimransp24
  161  ps -u gursimransp24> Assignment2.txt
  162  ps -u gursimransp24> file.txt
  163  vi Assignment2.txt
  164  ps -u gursimransp24> cs131>Assignment2> Assignment2.txt
  165  vi file.txt 
  166  cat cmds.log
  167  clear
  168  cd cs131
  169  cd Assignment2.txt
  170  cd Assignment2
  171  vi Assignment2.txt
  172  ps aux | grep [i]nit
  173  pgrep -x init
  174  ps aux|grep "1"
  175  ps -p 1
  176  systemd
  177  ps -pid 1
  178  ps --pid 1
  179  vi Assignment.txt
  180  vi Assignment2.txt
  181  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  182  cat ‘Global YouTube Statistics.csv.3’
  183  gursimransp24@sjsu Assignment2]$ cat ‘Global YouTube Statistics.csv.3’
  184  cat: ‘Global: No such file or directory
  185  cat: YouTube: No such file or directory
  186  cat: Statistics.csv.3’: No such file or directory
  187  [gursimransp24@sjsu Assignment2]$ 
  188  gursimransp24@sjsu Assignment2]$ cat ‘Global YouTube Statistics.csv.3’
  189  cat: ‘Global: No such file or directory
  190  cat: YouTube: No such file or directory
  191  cat: Statistics.csv.3’: No such file or directory
  192  [gursimransp24@sjsu Assignment2]$ 
  193  gursimransp24@sjsu Assignment2]$ cat ‘Global YouTube Statistics.csv’
  194  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv\
  195  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  196  ls -1
  197  cat 'Global YouTube Statistics.csv'
  198  cut -d ',' -f22,23 "Global YouTube Statistics.csv"
  199  cut -d ',' -f20,21 "Global YouTube Statistics.csv"
  200  cut -d ',' -f21,20 "Global YouTube Statistics.csv"
  201  tail -n +2
  202  cut -d ',' -f20,21 "Global YouTube Statistics.csv"
  203  cut -d ',' -f20,21 "Global YouTube Statistics.csv" | tail -n +2 | sort | uniq -c | sort -nr | head -n 3
  204  awk -F ',' 'NR > 1 {count[$20","$21]++} END {for (combo in count) print count[combo], combo}' "Global YouTube Statistics.csv" | sort -nr | head -n 3
  205  vi Assignment2.txt
  206  history > cmds.log
  207  cat cmds.log
  208  git add Assignment2
  209  git clone https://github.com/TheTechKnow/cs131.git
  210  git add Assignment2
  211  git status
  212  cd ..
  213  git add Assignment2
  214  git status
  215  git add Assignment2/Assignment2.txt
  216  git add Assignment1/cs131 cmds.log
  217  git add Assignment2/cs131 cmds.log
  218  git commit -m "Commiting the Assignment2"
  219  git status
  220  git push
  221  git pull
  222  git status
  223  git push
  224  cd cs131
  225  ls -l
  226  cd Assignment2
  227  cs -l
  228  ls -l
  229  mv 'Global YouTube Statistics.csv.5'>cs131
  230  cd ..
  231  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  232  cat ‘Global YouTube Statistics.csv’
  233  awk 'BEGIN {FS=":"} {if ($7== "/usr/sbin/nologin") print $0}' /etc/passwd
  234  awk 'BEGIN {FS=":"} {print $7}' /etc/passwd
  235  cat awkscr_if
  236  cd awk
  237  /etc/passwd
  238  clear
  239  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  240  ls -l
  241  cd cs131
  242  cd Worksheet3
  243  mkdir Worksheet3
  244  cd Worksheet3
  245  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/Global%20YouTube%20Statistics.csv
  246  cat ‘Global YouTube Statistics.csv’
  247  cat "Global YouTube Statistics.csv"
  248  grep -E 'United States|United Kingdom|India' Youtube2023Dataset.csv | sort -t ',' -k 7 -n -r > highest_monthly_earners.txt
  249  grep -E 'United States|United Kingdom|India' Global YouTube Statistics.csv | sort -t ',' -k 7 -n -r > highest_monthly_earners.txt
  250  grep -E 'United States|United Kingdom|India' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r > highest_monthly_earners.txt
  251  'grep -E 'United States|United Kingdom|India' | cut -d ',' -f16 "Global YouTube Statistics.csv" | tail -n +2 | sort | uniq -c | sort -nr | head -n 3
  252  '
  253  grep -E 'United States|United Kingdom|India' | cut -d ',' -f16 "Global YouTube Statistics.csv" | tail -n +2 | sort | uniq -c | sort -nr | head -n 3
  254  grep -E 'United States|United Kingdom|India'"Global YouTube Statistics.csv"| tail -n +2 | sort | uniq -c | sort -nr | head -n 3
  255  grep -E 'United States|United Kingdom|India' "Global YouTube Statistics.csv" | tail -n +2 | sort | uniq -c | sort -nr | head -n 3
  256  grep -E 'United States|United Kingdom|India' Global YouTube Statistics.csv | sort -t ',' -k 7 -n -r | awk -F ',' '{if ($1 == "United States" && NR==1) print "Highest earner from United States:", $3, "with earnings $", $7} {if ($1 == "United Kingdom" && NR==1) print "Highest earner from United Kingdom:", $3, "with earnings $", $7} {if ($1 == "India" && NR==1) print "Highest earner from India:", $3, "with earnings $", $7}'
  257  cd cs131
  258  cd Worksheet3
  259  grep -E 'United States|United Kingdom|India' Global YouTube Statistics.csv | sort -t ',' -k 7 -n -r | awk -F ',' '{if ($1 == "United States" && NR==1) print "Highest earner from United States:", $3, "with earnings $", $7} {if ($1 == "United Kingdom" && NR==1) print "Highest earner from United Kingdom:", $3, "with earnings $", $7} {if ($1 == "India" && NR==1) print "Highest earner from India:", $3, "with earnings $", $7}'
  260  grep -E 'United States|United Kingdom|India' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | awk -F ',' '{if ($1 == "United States" && NR==1) print "Highest earner from United States:", $3, "with earnings $", $7} {if ($1 == "United Kingdom" && NR==1) print "Highest earner from United Kingdom:", $3, "with earnings $", $7} {if ($1 == "India" && NR==1) print "Highest earner from India:", $3, "with earnings $", $7}'
  261  grep -E 'United States|United Kingdom|India' Youtube2023Dataset.csv > filtered_countries.csv
  262  grep -E 'United States|United Kingdom|India' Global YouTube Statistics.csv.csv > filtered_countries.csv
  263  ls -l
  264  grep -E 'United States|United Kingdom|India' 'Global YouTube Statistics.csv' > filtered_countries.csv
  265  sort -t ',' -k 7 -n -r filtered_countries.csv > sorted_earnings.csv
  266  for country in "United States" "United Kingdom" "India"; do     grep "$country" sorted_earnings.csv | head -n 1 > highest_earner_$country.txt; done
  267  cat country.txt
  268  ls -l
  269  cat highest_earner_India.txt
  270  cat highest_monthly_earners.txt
  271  {     grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | head -n 1;     grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | head -n 1;     grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | head -n 1;      grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 5 -n -r | head -n 1;     grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 5 -n -r | head -n 1;     grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 5 -n -r | head -n 1; } > ws3.txt
  272  cat ws3.txt
  273  {     grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | head -n 1 | cut -d ',' -f 8,7;      grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | head -n 1 | cut -d ',' -f 8,7;      grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 7 -n -r | head -n 1 | cut -d ',' -f 8,7;      grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 5 -n -r | head -n 1 | cut -d ',' -f 10,5;      grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 5 -n -r | head -n 1 | cut -d ',' -f 10,5;      grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 5 -n -r | head -n 1 | cut -d ',' -f 10,5; } >> combined_results.txt
  274  combined_results.txt
  275  cat combined_results.txt 
  276  {     grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 13 -n -r | head -n 1 | cut -d ',' -f 8,13;      grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 13 -n -r | head -n 1 | cut -d ',' -f 8,13;      grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 13 -n -r | head -n 1 | cut -d ',' -f 8,13;      grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3;      grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3;      grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3; } > combined_results.txt
  277  cat combined_results.txt 
  278  {     grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15;      grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15;      grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15;      grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3;      grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3;      grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3; } > combined_results.txt
  279  cat combined_results.txt 
  280  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15 > combined_results.txt
  281  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15 >> combined_results.txt
  282  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15 >> combined_results.txt
  283  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  284  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  285  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  286  cat combined_results.txt 
  287  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15 > combined_results.txt
  288  # Extract country name and earnings for United Kingdom
  289  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15 >> combined_results.txt
  290  # Extract country name and earnings for India
  291  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 15 -n -r | head -n 1 | cut -d ',' -f 8,15 >> combined_results.txt
  292  # Task 2: Finding the highest subscribed channel from three different categories
  293  # Extract category, YouTube, and subscribers for Sports
  294  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  295  # Extract category and subscribers for Education
  296  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  297  # Extract category and subscribers for Entertainment
  298  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  299  cat combined_results.txt 
  300  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 18 -n -r | head -n 1 | cut -d ',' -f 8,18 > combined_results.txt
  301  # Extract country name and earnings for United Kingdom
  302  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 18 -n -r | head -n 1 | cut -d ',' -f 8,18 >> combined_results.txt
  303  # Extract country name and earnings for India
  304  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 18 -n -r | head -n 1 | cut -d ',' -f 8,18 >> combined_results.txt
  305  # Task 2: Finding the highest subscribed channel from three different categories
  306  # Extract category, YouTube, and subscribers for Sports
  307  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  308  # Extract category and subscribers for Education
  309  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  310  # Extract category and subscribers for Entertainment
  311  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  312  cat combined_results.txt 
  313  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 > combined_results.txt
  314  # Extract country name and earnings for United Kingdom
  315  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  316  # Extract country name and earnings for India
  317  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  318  # Task 2: Finding the highest subscribed channel from three different categories
  319  # Extract category, YouTube, and subscribers for Sports
  320  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  321  # Extract category and subscribers for Education
  322  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  323  # Extract category and subscribers for Entertainment
  324  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,3 >> combined_results.txt
  325  cat combined_results.txt 
  326  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 > combined_results.txt
  327  # Extract country name and earnings for United Kingdom
  328  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  329  # Extract country name and earnings for India
  330  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  331  # Task 2: Finding the highest subscribed channel from three different categories
  332  # Extract category, YouTube, and subscribers for Sports
  333  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  334  # Extract category, YouTube, and subscribers for Education
  335  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  336  # Extract category, YouTube, and subscribers for Entertainment
  337  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  338  cat combined_results.txt 
  339  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 > combined_results.txt
  340  # Extract country name and earnings for United Kingdom
  341  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  342  # Extract country name and earnings for India
  343  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  344  # Task 2: Finding the highest subscribed channel from three different categories
  345  # Extract category, YouTube, and subscribers for Sports
  346  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  347  # Extract category, YouTube, and subscribers for Education
  348  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  349  # Extract category, YouTube, and subscribers for Entertainment
  350  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  351  cat combined_results.txt 
  352  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 > combined_results.txt
  353  # Extract country name and earnings for United Kingdom
  354  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  355  # Extract country name and earnings for India
  356  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  357  # Task 2: Finding the highest subscribed channel from three different categories
  358  # Extract category, YouTube, and subscribers for Sports
  359  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  360  # Extract category, YouTube, and subscribers for Education
  361  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  362  # Extract category, YouTube, and subscribers for Entertainment
  363  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  364  cat combined_results.txt 
  365  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 > combined_results.txt
  366  # Extract country name and earnings for United Kingdom
  367  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  368  # Extract country name and earnings for India
  369  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> combined_results.txt
  370  # Task 2: Finding the highest subscribed channel from three different categories
  371  # Extract category, YouTube, and subscribers for Sports
  372  grep 'Sports' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  373  # Extract category, YouTube, and subscribers for Education
  374  grep 'Education' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  375  # Extract category, YouTube, and subscribers for Entertainment
  376  grep 'Entertainment' "Global YouTube Statistics.csv" | sort -t ',' -k 3 -n -r | head -n 1 | cut -d ',' -f 5,2,3 >> combined_results.txt
  377  cat combined_results.txt 
  378  awk -F ',' '$5 == "Education" && $3 > max {max = $3; line = $5 "," $2 "," $3} END {print line}' "Global YouTube Statistics.csv" >> combined_results.txt
  379  cat combined_results.txt 
  380  awk -F ',' '$5 == "Sports" && $3 > max {max = $3; line = $5 "," $2 "," $3} END {print line}' "Global YouTube Statistics.csv" >> combined_results.txt
  381  awk -F ',' '$5 == "Entertainment" && $3 > max {max = $3; line = $5 "," $2 "," $3} END {print line}' "Global YouTube Statistics.csv" >> combined_results.txt
  382  cat combined_results.txt 
  383  ws3.txt
  384  ls -l
  385  grep 'United States' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 > ws3.txt
  386  grep 'United Kingdom' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> ws3.txt
  387  grep 'India' "Global YouTube Statistics.csv" | sort -t ',' -k 16 -n -r | head -n 1 | cut -d ',' -f 8,16 >> ws3.txt
  388  awk -F ',' '$5 == "Sports" && $3 > max {max = $3; line = $5 "," $2 "," $3} END {print line}' "Global YouTube Statistics.csv" >> ws3.txt
  389  awk -F ',' '$5 == "Education" && $3 > max {max = $3; line = $5 "," $2 "," $3} END {print line}' "Global YouTube Statistics.csv" >> ws3.txt
  390  awk -F ',' '$5 == "Entertainment" && $3 > max {max = $3; line = $5 "," $2 "," $3} END {print line}' "Global YouTube Statistics.csv" >> ws3.txt
  391  cat ws3.txt 
  392  rm combined_results.txt
  393  rm filtered_countries.csv
  394  rm highest_earner_India.txt
  395  rm highest_monthly_earners.txt
  396  rm sorted_earnings.csv
  397  ls -l
  398  vi ws3.txt 
  399  history > cmds.log
  400  ls -l
  401  git add 
  402  git add Worksheet3
  403  cd ..
  404  git add Worksheet3
  405  git commit -m "commiting the Worksheet 3"
  406  git push
  407  git status
  408  git pull
  409  git push
  410  echo "Hello, I'm <name>." | sed "s|<name>|$HOME|"
  411  echo "Hello, I'm <name>." | sed "s/<name>/$HOME/"
  412  echo "Hello, I'm <name>." | sed "s|<name>|$HOME|"
  413  awk 'BEGIN {print 'howdy, folks'}'
  414  awk "BEGIN {print 'howdy, folks'}"
  415  awk "BEGIN {print Hi}'
  416  awk 'BEGIN {print "howdy,\n folks"}'
  417  awk 'BEGIN {print "howdy, folks"}'
  418  awk 'BEGIN {print "howdy, $folks"}'
  419  awk -v PWD=$PWD "BEGIN {print PWD}"
  420  last
  421  /dev/pts
  422  #!/bin/bash
  423  hg
  424  vi Scriptfilename
  425  #!/bin/bash
  426  vi Scriptfilename.sh
  427  #!/bin/bash
  428  ~/.bash_profile
  429  pwd
  430  ls -la ~/.bash_profile
  431  vi ~/.bash_profile
  432  alias l='ls -ltr'
  433  alias w='ls -l | wc -l'
  434  source ~/.bash_profile
  435  l
  436  w
  437  mkdir Worksheet4/Subscribers
  438  mkdir -p Worksheet4/Subscribers
  439  cat 'Global YouTube Statistics.csv'
  440  grep "United States" YouTubers.csv | cut -d ',' -f 3 > Worksheet4/Subscribers/United_States.txt
  441  grep "United States" 'Global YouTube Statistics.csv' | cut -d ',' -f 4 > Worksheet4/Subscribers/United_States.txt
  442  grep "United States" 'Global YouTube Statistics.csv' | cut -d ',' -f 4 > Worksheet4/Subscribers/India.txt
  443  cat United_states.txt
  444  vi United_states
  445  cat United_States.txt
  446  grep "United States" 'Global YouTube Statistics.csv' | cut -d ',' -f 3 > Worksheet4/Subscribers/United_States.txt
  447  grep "India" 'Global YouTube Statistics.csv' | cut -d ',' -f 3 > Worksheet4/Subscribers/India.txt
  448  cat Worksheet4/Subscribers/United_States.txt
  449  cat Worksheet4/Subscribers/India.txt
  450  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' >> Worksheet4/ws4_means.txt
  451  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./; s/$/\/NR/' | bc -lq >> Worksheet4/ws4_means.txt
  452  echo "$(paste -sd+ Worksheet4/Subscribers/United_States.txt)" | bc -lq | sed 's/^\./0./' | awk '{print $0 / NR}' >> Worksheet4/ws4_means.txt
  453  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' > Worksheet4/Subscribers/US_mean.txt
  454  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' > temp_us_mean.txt
  455  total_us=$(sed 's/\n/+/g' temp_us_mean.txt)
  456  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' > temp_us_mean.txt
  457  total_us=$(sed 's/\n/+/g' temp_us_mean.txt)paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' > temp_us_mean.txt
  458  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' > temp_us_mean.txt
  459  total_us=$(paste -sd+ Worksheet4/Subscribers/United_States.txt)
  460  count_us=$(wc -l < Worksheet4/Subscribers/United_States.txt)
  461  echo "$total_us/$count_us" | bc -lq | sed 's/^\./0./' >> Worksheet4/ws4_means.txt
  462  echo "scale=2; $total_us / $count_us" | bc | sed 's/^\./0./' >> Worksheet4/ws4_means.txt
  463  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq | sed 's/^\./0./' > us_mean.txt
  464  paste -sd+ Worksheet4/Subscribers/United_States.txt | bc -lq > Worksheet4/Subscribers/US_mean.txt
  465  vi greetings.txt
  466  sed -i 's/Hello/Hi/g' greetings.txt
  467  cat greetings.txt 
  468  sed -i '/Doe/d' greetings.txt
  469  cat greetings.txt 
  470  sed -i 's/$/ (edited)/' greetings.txt
  471  cat greetings.txt 
  472  sed -i '/^Hello,.*Michael Johnson/s/Michael Johnson/Mike Johnson/' greetings.txt
  473  cat greetings.txt 
  474  ls -1
  475  cd cs131
  476  cd Worksheet4
  477  mkdir Worksheet4
  478  cd ..
  479  cd .
  480  cd..
  481  ls -1
  482  cd Worksheet4
  483  ls -l
  484  cd Subscribers/
  485  ls -l
  486  rm US_mean.txt 
  487  ls -l
  488  cd ..
  489  pwd
  490  cd..
  491  cd ..
  492  pwd
  493  mv greetings.txt Worksheet4/
  494  cd Worksheet4
  495  ls -l
  496  total_us=$(paste -sd+ Worksheet4/Subscribers/United_States.txt)
  497  cd ..
  498  total_us=$(paste -sd+ Worksheet4/Subscribers/United_States.txt)
  499  count_us=$(wc -l < Worksheet4/Subscribers/United_States.txt)
  500  echo "scale=2; $total_us / $count_us" | bc -lq > Worksheet4/ws4_means.txt
  501  echo "$total_us / $count_us" | awk '{ printf "%.2f\n", $1 }' > Worksheet4/ws4_means.txt
  502  cat ws4_means.txt
  503  cd Worksheet4
  504  cat ws4_means.txt
  505  total_India=$(paste -sd+ Worksheet4/Subscribers/India.txt)
  506  cd ..
  507  total_India=$(paste -sd+ Worksheet4/Subscribers/India.txt)
  508  echo "scale=2; $total_India / $count_India" | bc -lq > Worksheet4/ws4_means.txt
  509  count_india=$(wc -l < Worksheet4/Subscribers/India.txt)
  510  echo "$total_india / $count_india" | awk '{ printf "%.2f\n", $1 }' >> Worksheet4/ws4_means.txt
  511  cd Worksheet4
  512  cat ws4_means.txt 
  513  total_us=$(paste -sd+ Worksheet4/Subscribers/United_States.txt)
  514  cd ..
  515  total_us=$(paste -sd+ Worksheet4/Subscribers/United_States.txt)
  516  count_india=$(wtotal_india=$(paste -sd+ Worksheet4/c -l < Worksheet4/Subscribers/Un.txt)
  517  echo "$total_us / $count_us" | awk '{ printf "%.2f\n", $1 }' > Worksheet4/ws4_means.txt
  518  total_india=$(paste -sd+ Worksheet4/Subscribers/United_States.txt)
  519  total_india=$(paste -sd+ Worksheet4/Subscribers/India.txt)
  520  count_india=$(wc -l < Worksheet4/Subscribers/India.txt)
  521  echo "$total_india / $count_india" | awk '{ printf "%.2f\n", $1 }' >> Worksheet4/ws4_means.txt
  522  cd Worksheet4
  523  cat ws4_means.txt 
  524  ls -l
  525  clear
  526  script ws4.txt
  527  cat ws4.txt
  528  ls -l
  529  cd Worksheet4
  530  ls -l
  531  mv ws4.txt Worksheet4/
  532  cd ..
  533  mv ws4.txt Worksheet4/
  534  cd Worksheet4
  535  ls -l
  536  cd ..
  537  cd cs131
  538  ls -l
  539  cd Worksheet4
  540  ls -l
  541  cd ..
  542  rm Worksheet4
  543  rmdir Worksheet4
  544  ls -l
  545  cd ..
  546  mv Worksheet4 cs131
  547  cd cs131
  548  ls -l
  549  cd Worksheet4
  550  ls -l
  551  cd ..
  552  git add Worksheet4
  553  git status
  554  git commit" add the worksheet4"
  555  git commit -m "commiting the worksheet4"
  556  git status
  557  git push
  558  git pull
  559  git push
  560  sed 's/Pineapple/Feta/' tops.txt 
  561  touch tops.txt
  562  vi tops.txt
  563  sed 's/Pineapple/Feta/' tops.txt 
  564  sed 's/Pineapple/Feta/g' tops.txt
  565  sed 's.Pineapple.Feta.' tops.txt
  566  vi tops.txt
  567  sed 's.Pineapple.Feta.' tops.txt
  568  sed 's|Pineapple|Feta|' tops.txt 
  569   sed ‘/Pineapples/ d’ tops.txt
  570  sed ‘/Pineapples/ d’ tops.txt
  571   sed '3 d' tops.txt
  572  sed 's/Pineapples/Half &/' tops.txt
  573  sed 'Pq' tops.txt
  574  sed '3q' tops.txt
  575  touch *
  576  ls -l
  577  touch *.txt
  578  ls -l
  579  vi *.txt
  580  ls -l
  581   rm 
  582   rm *.txt
  583  touch text.txt
  584  ls -l
  585  cd ..
  586  ls -l
  587  cd gursimranp24
  588  cd ..
  589  home
  590  ~
  591  echo home
  592  awk '/Pineapples/' tops.txt
  593  cat tops.txt
  594  ls -l
  595  cd cs131
  596  ls -l
  597  cd ..
  598  vi text.txt
  599  awk '/Pineapples/' text.txt
  600  cat
  601  cat text.txt
  602  vi text.txt 
  603  awk '/Pineapples/' text.txt
  604  awk -F: '{print $1}' /etc/passwd
  605  awk -F: '{print $5 ; print $6; print$7}'
  606  awk -F: '{print $5 ; print $6; print$7}' /etc/passwd
  607  awk '/Pineapples/ { print }' text.txt
  608  awk 'BEGIN {lc=0} // {lc++} END {print lc}' text.txt
  609  cat text.txt
  610  awk 'BEGIN {i=1} i<4 {print; i++}' text.txt
  611  awk 'BEGIN {FS=","; OFS="\t"} {print $1, $2}' text.txt
  612  awk 'END { print "Total number of records: " NR }' text.txt
  613  awk '{ print "Line " NR ": " $0 }' text.txt
  614  awk -v user=jyotika -f awkscr_option-v /etc/passwd
  615  awk 'BEGIN {FS=":"} {print $1, " uses ", $7}' /etc/passwd
  616  awk 'BEGIN {FS=":"} {if ($7 == "/usr/sbin/nologin") print $0}'
  617  awk 'BEGIN {FS=":"} {if ($7 == "/usr/sbin/nologin") print $0}' /etc/passwd
  618  awk ‘BEGIN {print int(57.43)}’
  619  awk ‘BEGIN {print sqrt(25)}’
  620  awk '{ if (length ($0)) print }' text.txt
  621  awk -F : '{ if(index($0, "bash")) print}' /etc/passwd
  622  $ awk -F : '{ print tolower ($5)}' /etc/passwd
  623  awk -F : '{ print toupper ($5)}' /etc/passwd
  624  `
  625  awk -F : '{ if (match ($0, "bash")) print $1 " uses "
  626  $7}' /etc/passwd
  627  awk '{split ($0, all, ":"); print all[1], " is known
  628  as " all[5]}' /etc/passwd
  629  awk '{split ($0, all, ":"); print all[1], " is known
  630  as " all[5]}' /etc/passwd
  631  awk '{split ($0, all, ":"); print all[1], " is known
  632  as " all[5]}' /etc/passwd
  633  awk '{split ($0, all, ":"); print all[1], "is known as" all[5]}' /etc/passwd
  634  echo "Hello, I'm <name>." | sed "s/<name>/$HOME/"
  635  echo "Hello, I'm <name>." | sed "s|<name>|$HOME|"
  636  cat pos.sh
  637  touch pos.sh
  638  cat pos.sh
  639  cd pos.sh
  640  vi pos.sh 
  641  ls
  642  cat pos.sh
  643  bash pos.sh Coffee
  644  bash pos.sh 
  645  *
  646  cs 131`
  647  cd cs 131
  648  cd cs131
  649  *
  650  $*
  651  $$
  652  cd ..
  653  $*
  654  $$
  655  bash $$
  656  echo $*
  657  echo $$
  658  echo $?
  659  read A B 
  660  echo $A
  661  read A B C
  662  #! /bin/bash
  663  echo "who am I talking to?"
  664  read user_name
  665  echo "Hello $user_name"
  666  echo "with $user_name"
  667  echo $?
  668  ls
  669  touch variables.sh
  670  vi variables.sh 
  671  echo $count
  672  bash variables.sh 
  673  $PATH
  674  a=10
  675  echo $a
  676  touch local variable
  677  rm local variable
  678  touch local_variable.sh
  679  cat local_variable.sh 
  680  vi local_variable.sh 
  681  bash local_variable.sh 
  682  vi local_variable.sh 
  683  bash local_variable.sh 
  684  echo $FAV_CHARACTER
  685  ls
  686  mkdir Scripts
  687  mv local_variable.sh Scripts
  688  ls
  689  mv pos.sh Scripts
  690  mv variables.sh Scripts
  691  cd Scripts
  692  ls
  693   a=1+2
  694  echo $a
  695  a=`expr 1+2`
  696  echo $a
  697  a = `expr 1 + 2`
  698  a = `$expr 1 + 2`
  699  a=`expr 1 + 2`
  700  echo $a
  701  touch areaOfRectangle
  702  vi areaOfRectangle 
  703  car areaOfRectangle 
  704  cat areaOfRectangle 
  705  ./areaOfRectangle
  706  ls
  707  ls areaOfRectangle 
  708  bash 
  709  ls -l
  710  ./areaOfRectangle
  711  vi areaOfRectangle 
  712  ./areaOfRectangle
  713  cd cs131
  714  mkdir Assignment3
  715  cd Assignment3
  716  man last
  717  cat last
  718  last
  719  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/last.fake
  720  wget https://raw.githubusercontent.com/jyotikahp/DemoRepoForCS131/main/passwd.fake
  721  cat last.fake
  722  wc -l last.fake
  723  grep 'sp24' last.fake > lastsp24.fake
  724  cat lastsp24.fake 
  725  wc -l lastsp24.fake 
  726  wc -l last.fake
  727  sed -n '/sp24/!p' last.fake | wc -l
  728  grep 'Sun' lastsp24.fake
  729  awk '{print $1}' lastsp24.fake
  730  awk '{print $1}' lastsp24.fake | sort | uniq
  731  awk '{print $1}' lastsp24.fake | wc -l
  732  awk '{print $1}' lastsp24.fake | sort | uniq | wc -l
  733  grep 'Sun' lastsp24.fake | awk '{print $1}' lastsp24.fake
  734  grep 'Sun' lastsp24.fake | awk '{print $1}'
  735  grep 'Sun' lastsp24.fake | awk '{print $1}' | sort | uniq
  736  awk '/Sun/ {print $1} END {print "Kudos to these people for putting in the work"}' lastsp24.fake | sort | uniq
  737  awk '/Sun/ {print $1} END {if (NR>0) print "Kudos to these people for putting in the work"}' lastsp24.fake | sort | uniq
  738  awk 'BEGIN {print "The list of people who worked on Sunday are:"} /Sun/ {print $1} END {if (NR>0) print "Kudos to these people for putting in the work"}' lastsp24.fake | sort | uniq
  739  awk 'BEGIN {print "The list of people who worked on Sunday are:"} /Sun/ {users[$1]} END {for (user in users) print user; if (length(users) > 0) print "Kudos to these people for putting in the work"}' lastsp24.fake | sort | uniq
  740  awk 'BEGIN {print "The list of people who worked on Sunday are:"} /Sun/ {print $1} END {if (NR>0) print "Kudos to these people for putting in the work"}' lastsp24.fake
  741  awk 'BEGIN {print "The list of people who worked on Sunday are:"} /Sun/ {print $1} END {if (NR>0) print "Kudos to these people for putting in the work"}' lastsp24.fake|uniq
  742  touch Assignment3.txt
  743  vi Assignment3.txt 
  744  grep 'Sun' lastsp24.fake | awk '{print $1}' | sort | uniq > last1.fake
  745  awk 'BEGIN {print "The list of people who worked on Sunday are:"} /Sun/ {print $1} END {if (NR>0) print "Kudos to these people for putting in the work"}' last1.fake 
  746  vi Assignment3.txt 
  747  awk '{split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1}' lastsp24.fake | sort | uniq
  748  vi Assignment3.txt 
  749  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq
  750  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | uniq
  751  awk '{split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1}' lastsp24.fake | sort | uniq |wc -l
  752  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | uniq | wc -l
  753  awk 'BEGIN {print "The list of people who worked on Sunday are:"} /Sun/ {print $1} END {if (NR>0) print "Kudos to these people for putting in the work"}' lastsp24.fake|uniq
  754  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq 
  755  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq
  756  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort -u
  757  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq
  758  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) users[$1]} END {for (user in users) print user; if (length(users) > 0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq
  759  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | uniq
  760  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | uniq |wc -l
  761  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | uniq |sort
  762  awk 'BEGIN {print "Night Owls List:"} '{split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1}'END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq
  763  awk 'BEGIN {print "Night Owls List:"} {split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1} END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}' lastsp24.fake | sort | uniq
  764  awk '{split($5, a, ":"); if ((a[1] >= 23) || (a[1] <= 4)) print $1}' lastsp24.fake | sort | uniq | awk 'BEGIN {print "Night Owls List:"} {print} END {if (NR>0) print "Night Owls are dope. Please ensure you get enough sleep though."}'
  765  vi Assignment3.txt 
  766  awk '{split($5, a, ":"); if ((a[1] >= 5) && (a[1] <= 9)) print $1}' lastsp24.fake | sort | uniq | awk 'BEGIN {print "Early Birds List:"} {print} END {if (NR>0) print "Early Birds are dope. Please ensure you get enough sleep though."}'
  767  vi Assignment3.txt 
  768  awk '/^t/' lastsp24.fake
  769  awk '/^t/ {print $1}' lastsp24.fake
  770  awk '/^t/ {print $1}' lastsp24.fake | sort | uniq
  771  vi Assignment3.txt 
  772  cat passwd.fake 
  773  awk -F: '$1 ~ /^a/ && $3 % 2 == 0 {print $1}' passwd.fake
  774  vi Assignment3.txt 
  775  sed 's/[a-zA-Z0-9[:space:]]//g' passwd.fake | sed '/^$/d' | sort -u
  776  sed '/[[:alnum:][:space:]]/d' passwd.fake | sort -u
  777  sed '/[a-zA-Z0-9 ]/d' passwd.fake | sed '/^$/d' | sort -u
  778  sed 's/[a-zA-Z0-9[:space:]]//g' passwd.fake | sed '/^$/d' | sort -u
  779  vi Assignment3.txt 
  780  ls -l
  781  ls
  782  history >> cmds.log
  783  ls
  784  cd ..
  785  git add Assignment3
  786  cd cs131
  787  git add Assignment3
  788  git status
  789  git commit -m "Commiting the Assignment3"
  790  git status
  791  git push
  792  git pull
  793  git status
  794  git push
  795  add() { local sum $(( $1 + $2)); echo $sum; return 0; }
  796  add 3 5
  797  result=$(add 3 5 )
  798  echo " Result: $result"
  799  wget https://www.kaggle.com/datasets/ronaldonyango/global-jobs-and-salaries-2024
  800  cat global-jobs-and-salaries-2024 
  801  wget https://www.kaggle.com/datasets/ronaldonyango/global-jobs-and-salaries-2024
  802  cat global-jobs-and-salaries-2024
  803  wget https://www.kaggle.com/datasets/ronaldonyango/global-jobs-and-salaries-2024?select=global_jobs_salaries_2024.csv#:~:text=calendar_view_week-,global_jobs_salaries_2024,-.csv
  804  cat global-jobs-and-salaries-2024.csv
  805  cat global_jobs_salaries_2024.csv
  806  cat global-jobs-and-salaries-2024
  807  wget https://www.kaggle.com/datasets/ronaldonyango/global-jobs-and-salaries-2024?select=global_jobs_salaries_2024.csv#:~:text=calendar_view_week-,global_jobs_salaries_2024.csv
  808  ls 
  809  ls -l
  810  cat global-jobs-and-salaries-2024?select=global_jobs_salaries_2024.csv
  811  wget global_jobs_salaries_2024.csv
  812  wget https://www.kaggle.com/datasets/ronaldonyango/global-jobs-and-salaries-2024/global_jobs_salaries_2024.csv
  813  ls -l
  814  wget https://www.kaggle.com/datasets
  815  ls -l
  816  cd datasets
  817  cat datasets 
  818  wget https://www.kaggle.com/datasets/ronaldonyango/global-jobs-and-salaries-2024
  819  ls -l
  820  cat global-jobs-and-salaries-2024
  821  scp /Users/gursimrankaur/Downloads gursimransp24@172.20.25.9
  822  nano ~/.bashrc
  823  alias ls='ls -latr'
  824  source ~/.bashrc
  825  alias ls='ls'
  826  source ~/.bashrc
  827  mkdir .kaggle
  828  ls -l
  829  ls -la
  830  scp "/Users/gursimrankaur/Downloads/global_jobs_salaries_2024 2.csv" gursimransp24@172.20.25.9:datasets
  831  cd ..
  832  ls -l
  833  cat 'global_jobs_salaries_2024 2.csv'
  834  head 'global_jobs_salaries_2024 2.csv'
  835  wc -l 'global_jobs_salaries_2024 2.csv'
  836  head -n 1 'global_jobs_salaries_2024 2.csv' | tr ',' '\n'
  837  awk -F ',' 'NR > 1 {sum += $4; sumsq += ($4)^2} END {mean = sum / NR; stdev = sqrt(sumsq / NR - mean^2); print "Mean:", mean, "Standard Deviation:", stdev}' 'global_jobs_salaries_2024 2.csv'
  838  awk -F ',' 'NR > 1 {if (NR == 2) {min = max = $4} else {if ($4 < min) min = $4; if ($4 > max) max = $4}} END {print "Minimum Salary:", min, "Maximum Salary:", max}' 'global_jobs_salaries_2024 2.csv'
  839  awk -F ',' 'NR > 1 {if (NR == 2) {min = max = $7} else {if ($7 < min) min = $7; if ($7 > max) max = $7}} END {print "Minimum Salary:", min, "Maximum Salary:", max}' 'global_jobs_salaries_2024 2.csv'
  840  awk -F ',' 'NR > 1 {country_salary[$2] += $7} END {for (country in country_salary) print country, country_salary[country]}' 'global_jobs_salaries_2024 2.csv' | sort -k2 -nr | head -n 10
  841  awk -F ',' 'NR > 1 {country_salary[$2] += $4} END {for (country in country_salary) print country, country_salary[country]}' 'global_jobs_salaries_2024 2.csv' | sort -k2 -nr | head -n 10
  842  awk -F ',' 'NR > 1 {country_salary[$2] += $7} END {for (country in country_salary) print country, country_salary[country]}' 'global_jobs_salaries_2024 2.csv' | sort -k2 -nr | head -n 10| awk '{print NR ".", $1, "-", $2}'
  843  cd cs131
  844  mkDir
  845  mkdir CS131ClassProjectX
  846  cd ..
  847  ls -l
  848  mv 'global_jobs_salaries_2024 2.csv' CS131ClassProjectX
  849  cd cs131
  850  cd CS131ClassProjectX
  851  ls -l
  852  cd ..
  853  mv global_jobs_salaries_2024\ 2.csv CS131ClassProjectX/
  854  mv 'global_jobs_salaries_2024 2.csv' cs131
  855  ls -l
  856  cd ..
  857  mv 'global_jobs_salaries_2024 2.csv' cs131
  858  ls -l
  859  mv 'global_jobs_salaries_2024 2.csv' CS131ClassProjectX
  860  cd CSCS131ClassProjectX
  861  cd CS131ClassProjectX
  862  cat CS131ClassProjectX
  863  ls -l
  864  mv CS131ClassProjectX global_jobs_salaries_2024.csv
  865  ls -l
  866  global_jobs_salaries_2024\ 2.csv cs131/
  867  global_jobs_salaries_2024\ 2\.csv cs131/
  868  global_jobs_salaries_2024\ .csv cs131/
  869  global_jobs_salaries_2024\.csv cs131/
  870  mv global_jobs_salaries_2024.csv cs131/
  871  cd cs131
  872  ls -l
  873  mv global_jobs_salaries_2024.csv CS131ClassProjectX/
  874  cd CS131ClassProjectX
  875  ls -l
  876  history>cmds.log
  877  ls -l
  878  cat cmds.log
  879  awk -F ',' '{print $1 "," $2 "," $7}' 'global_jobs_salaries_2024 2.csv' | awk -F ',' '$3 != ""' | sort -t',' -k1,1 -k3,3nr | awk -F ',' '!seen[$1]++' | awk -F ',' '{print "Country:", $1, "- Highest Paying Job:", $2, "- Salary (USD):", $3}'
  880  awk -F ',' '{print $1 "," $2 "," $7}' 'global_jobs_salaries_2024.csv'
  881  cd cs131
  882  cd CS131ClassProjectX
  883  awk -F ',' '{print $1 "," $2 "," $7}' 'global_jobs_salaries_2024.csv'| awk -F ',' '$3 != ""' | sort -t',' -k1,1 -k3,3nr | awk -F ',' '!seen[$1]++' | awk -F ',' '{print "Country:", $1, "- Highest Paying Job:", $2, "- Salary (USD):", $3}'
  884  awk -F ',' '$1 == "India" && $3 != ""' 'global_jobs_salaries_2024.csv' | sort -t',' -k3,3nr | head -n 1 | awk -F ',' '{print "Highest Paying Job in India:", $2, "- Salary (USD):", $3}'
  885  awk -F ',' '$1 == "India" && $3 != ""' 'global_jobs_salaries_2024.csv' | sort -t',' -k3,3nr | head -n 1 | awk -F ',' '{print "Highest Paying Job in India:", $2, "- Salary (USD):", $7}'
  886  awk -F ',' '$1 == "India" && $7 != ""' 'global_jobs_salaries_2024.csv' | sort -t',' -k3,3nr | head -n 1 | awk -F ',' '{print "Highest Paying Job in India:", $2, "- Salary (USD):", $7}'
  887  awk -F ',' '$1 == "India" && $7 != ""' 'global_jobs_salaries_2024.csv' | sort -t',' -k7,7nr | head -n 1 | awk -F ',' '{print "Highest Paying Job in India:", $2, "- Salary (USD):", $7}'
  888  awk -F ',' '$1 == "Zimbabwe" && $7 != ""' 'global_jobs_salaries_2024.csv' | sort -t',' -k7,7nr | head -n 1 | awk -F ',' '{print "Highest Paying Job in India:", $2, "- Salary (USD):", $7}'
  889  cmds.log
  890  cd cs131
  891  cmds.log
  892  cd CS131ClassProjectX/
  893  cat cmds.log
  894  sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{count[$3]++; sum[$3]+=$7} END {for (category in count) print category, count[category], sum[category]/count[category]}' | sort -k3,3nr | head -n 10
  895  sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{count[$3]++; sum[$3]+=$7} END {for (category in count) print "Category:", category, "- Count of jobs in category:", count[category], "- Average salary:", sum[category]/count[category]}' | sort -k5,5nr | head -n 10
  896  sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{count[$3]++; sum[$3]+=$7} END {for (category in count) print count[category], category, sum[category]/count[category]}' | sort -nr | head -n 10 | awk '{print "Category:", $2, "- Count of jobs in category:", $1, "- Average salary:", $3}'
  897  sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{count[$3]++; sum[$3]+=$7} END {for (category in count) print count[category], category, sum[category]/count[category]}' | sort -nr | head -n 10 | awk '{print "Category:", $2, "- Count of jobs in category:", $1, "- Average salary:", $3}'
  898  sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{
  899      count[$3]++;
  900      sum[$3] += ($7 ~ /^[0-9]*(\.[0-9]+)?$/) ? $7 : 0;  # Add only if salary is a valid number
  901  } 
  902  END {
  903      for (category in count) {
  904          if (count[category] > 0) {
  905              avg_salary = sum[category] / count[category];
  906              printf "Category: %s - Count of jobs in category: %d - Average salary: %.2f\n", category, count[category], avg_salary;
  907          }
  908      }
  909  }' | sort -nr | head -n 10
  910  sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{
  911      count[$3]++;
  912      sum[$3] += ($7 ~ /^[0-9]*(\.[0-9]+)?$/) ? $7 : 0;  # Add only if salary is a valid number
  913  } 
  914  END {
  915      for (category in count) {
  916          if (count[category] > 0) {
  917              avg_salary = sum[category] / count[category];
  918              printf "%d %s %.2f\n", count[category], category, avg_salary;
  919          }
  920      }
  921  }' | sort -nrk1,1 -k3,3nr | head -n 10 | awk '{print "Category:", $2, "- Count of jobs in category:", $1, "- Average salary:", $3}'
  922  sed '1d' 'global_jobs_salaries_2024.csv' | > awk -F ',' '{
  923  >     count[$3]++;
  924  >     sum[$3] += ($7 ~ /^[0-9]*(\.[0-9]+)?$/) ? $7 : 0;  # Add only if salary is a valid number
  925  > } 
  926  > END {
  927  >     for (category in count) {
  928  >         if (count[category] > 0) {
  929  >             avg_salary = sum[category] / count[category];
  930  >             printf "%d %s %.2f\n", count[category], category, avg_salary;
  931  >         }
  932  >     }
  933  > }' | sort -nrk1,1 -k3,3nr | head -n 10 | awk '{print "Category:", $2, "- Count of jobs in category:", $1
  934  ;
  935  }
  936  '
  937  sed '1d' 'global_jobs_salaries_2024.csv' | > awk -F ',' '{count[$3]++; sum[$3]+=$7} END {for (category in count) print count[category], category, sum[category]/count[category]}' | > sort -nr | head -n 10 | awk '{print "Category:", $2, "- Count of jobs in category:", $1}'
  938  sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{
  939      count[$3]++;
  940      sum[$3] += ($7 ~ /^[0-9]*(\.[0-9]+)?$/) ? $7 : 0;  # Add only if salary is a valid number
  941  } 
  942  END {
  943      for (category in count) {
  944          if (count[category] > 0) {
  945              avg_salary = sum[category] / count[category];
  946              printf "%d %s %.2f\n", count[category], category, avg_salary;
  947          }
  948      }
  949  }' | sort -nrk1,1 -k3,3nr | head -n 10 | awk '{print "Category:", $2, "- Count of jobs in category:", $1, "- Average salary:", $3}'
  950  wc -l global_jobs_salaries_2024.csv
  951  wc -l
  952  history>cmds.log
  953  cd CS131
  954  awk -F ',' '$1 != "Country" && $7 != ""' 'global_jobs_salaries_2024.csv' | sort -t',' -k1,1 -k7,7n | awk -F ',' '($1 != prev_country) {print "Country:", $1, "- Lowest Salary (USD):", $7; prev_country = $1}'
  955  cd cs131
  956  cd CS131ClassProjectX/
  957  awk -F ',' '$1 != "Country" && $7 != ""' 'global_jobs_salaries_2024.csv' | sort -t',' -k1,1 -k7,7n | awk -F ',' '($1 != prev_country) {print "Country:", $1, "- Lowest Salary (USD):", $7; prev_country = $1}'
  958  awk -F ',' '$3 != ""' 'global_jobs_salaries_2024.csv' | sort -t',' -k3,3nr | awk -F ',' '!seen[$3]++' | head -n 10 | awk -F ',' '{print "Job Category:", $3, "- Highest Salary (USD):", $7}'
  959  awk -F ',' '$3 != ""' 'global_jobs_salaries_2024.csv' |  sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{count[$3]++; sum[$3]+=$7} END {for (category in count) print category, sum[category]/count[category]}' | sort -k2,2nr | head -n 10
  960  sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{count[$3]++; sum[$3]+=$7} END {for (category in count) print category, sum[category]/count[category]}' | sort -k2,2nr | head -n 10
  961  history>cmds.log
  962  cut -d ',' -f 1 global_jobs_salaries_2024.csv | sort | uniq
  963  cut -d ',' -f 7 global_jobs_salaries_2024.csv | sort -n
  964  awk 'NR==1 {lowest=$1} END {print "Lowest Salary (USD):", lowest, "- Highest Salary (USD):", $NF}'
  965  cut -d ',' -f 7 global_jobs_salaries_2024.csv | sort -n |sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{count[$3]++; sum[$3]+=$7} END {for (category in count) print "Category:", category, "- Count of jobs in category:", count[category], "- Average salary:", sum[category]/count[category]}' |  ;
  966  cut -d ',' -f 7 global_jobs_salaries_2024.csv | sort -n|awk 'NR==1 {lowest=$1} END {print "Lowest Salary (USD):", lowest, "- Highest Salary (USD):", $NF}'
  967  cut -d ',' -f 7 global_jobs_salaries_2024.csv | sort -n | awk 'NR==1 {lowest=$1} END {print "Lowest Salary (USD):", lowest, "- Highest Salary (USD):", $NF}'
  968  sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{print $7}' | sort -n | awk 'NR==1 {lowest=$1} END {print "Lowest Salary (USD):", lowest, "- Highest Salary (USD):", $NF}'
  969  sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{
  970      count[$3]++;
  971  } 
  972  END {
  973      for (category in count) {
  974          printf "%d %s\n", count[category], category;
  975      }
  976  }' | sort -nrk1,1 | head -n 10 | awk '{print "Category:", $2, "- Count of jobs in category:", $1}'
  977  sed '1d' 'global_jobs_salaries_2024.csv' | awk -F ',' '{
  978      count[$3]++;
  979  } 
  980  END {
  981      for (category in count) {
  982          printf "%d %s\n", count[category], category;
  983      }
  984  }' | sort -nrk1,1 | head -n 10 | awk '{print "Category:", $2, "- Count of jobs in category:", $1}'
  985  awk -F ',' 'NR > 1 { count[$3]++ } END { for (category in count) print count[category], category }' global_jobs_salaries_2024.csv | sort -nr | head -n 10 | awk '{ print "Category:", $2, "- Count of jobs in category:", $1 }'
  986  history>cmds.log
  987  cut -d ',' -f 7 global_jobs_salaries_2024.csv | sort -n | head -n 1
  988  cut -d ',' -f 7 global_jobs_salaries_2024.csv | sort -n | head -n 2
  989  plt.figure(figsize=(12, 6))
  990  plt.bar(df["Country"], df["Salary (USD)"])
  991  plt.xlabel("Country")
  992  plt.ylabel("Exchanged Salary Rate (USD)")
  993  plt.title("Exchanged Salary Rates by Country")
  994  plt.xticks(rotation=90)  # Rotate x-axis labels for better readability
  995  cd cs131
  996  ls -l
  997  mkdir Worksheet5
  998  cd Worksheet5
  999  touch script.sh
 1000  vi script.sh 
 1001  cd ..
 1002  touch script.sh
 1003  vi script.sh 
 1004  cat 'Global YouTube Statistics.csv' 
 1005  vi script.sh 
 1006  bash script.sh 
 1007  wc -l Workhsheet\ 5/United\ States/Music.txt Workhsheet\ 5/United\ States/Entertainment.txt Workhsheet\ 5/United\ States/Gaming.txt Workhsheet\ 5/United\ States/Comedy.txt > ws5.txt
 1008  bash script.sh 
 1009  wc -l Workhsheet\ 5/United\ States/Music.txt Workhsheet\ 5/United\ States/Entertainment.txt Workhsheet\ 5/United\ States/Gaming.txt Workhsheet\ 5/United\ States/Comedy.txt > ws5.txt
 1010  mv script.sh Worksheet5
 1011  cd Worksheet5
 1012  bash script.sh 
 1013  mv 'Global YouTube Statistics.csv' Worksheet5
 1014  cd ..
 1015  mv 'Global YouTube Statistics.csv' Worksheet5
 1016  cd Worksheet5
 1017  bash script.sh 
 1018  wc -l Workhsheet\ 5/United\ States/Music.txt Workhsheet\ 5/United\ States/Entertainment.txt Workhsheet\ 5/United\ States/Gaming.txt Workhsheet\ 5/United\ States/Comedy.txt > ws5.txt
 1019  wc -l Worksheet\ 5/United\ States/Music.txt Worksheet\ 5/United\ States/Entertainment.txt Worksheet\ 5/United\ States/Gaming.txt Worksheet\ 5/United\ States/Comedy.txt > ws5.txt
 1020  wc -l Worksheet5/United\ States/Music.txt Worksheet5/United\ States/Entertainment.txt Worksheet5/United\ States/Gaming.txt Worksheet5/United\ States/Comedy.txt > ws5.txt
 1021  mkdir -p "Workhsheet 5/United States/"
 1022  ls -l
 1023  mkdir United States
 1024  wc -l Worksheet5/United\ States/Music.txt Worksheet5/United\ States/Entertainment.txt Worksheet5/United\ States/Gaming.txt Worksheet5/United\ States/Comedy.txt > ws5.txt
 1025  wc -l "Worksheet5/United States/Music.txt" "Worksheet5/United States/Entertainment.txt" "Worksheet5/United States/Gaming.txt" "Worksheet5/United States/Comedy.txt" > ws5.txt
 1026  wc -l "United States/Music.txt" "United States/Entertainment.txt" "United States/Gaming.txt" "United States/Comedy.txt" > ws5.txt
 1027  cat script.sh
 1028  vi script.sh 
 1029  bash script.sh 
 1030  wc -l "United States/Music.txt" "United States/Entertainment.txt" "United States/Gaming.txt" "United States/Comedy.txt" > ws5.txt
 1031  vi script.sh 
 1032  bash script.sh 
 1033  wc -l "United States/Music.txt" "United States/Entertainment.txt" "United States/Gaming.txt" "United States/Comedy.txt" > ws5.txt
 1034  cat script.sh 
 1035  vi script.sh 
 1036  bash script.sh 
 1037  wc -l "United States/Music.txt" "United States/Entertainment.txt" "United States/Gaming.txt" "United States/Comedy.txt" > ws5.txt
 1038  vi script.sh 
 1039  wc -l "United States/Music.txt" "United States/Entertainment.txt" "United States/Gaming.txt" "United States/Comedy.txt" > ws5.txt
 1040  ls -l
 1041  cat ws5.txt 
 1042  mkdir "United States"
 1043  ls -l
 1044  mkdir United\ States
 1045  bash script.sh 
 1046  wc -l "United States/Music.txt" "United States/Entertainment.txt" "United States/Gaming.txt" "United States/Comedy.txt" > ws5.txt
 1047  rm 'United States'
 1048  rm -r 'United States'
 1049  mkdir United\ States
 1050  ls -l
 1051  cd United States
 1052  cd 'United States'
 1053  ls -l
 1054  cd ..
 1055  cat script.sh 
 1056  bash script.sh 
 1057  wc -l "Workhsheet 5/United States/Music.txt"
 1058  wc -l "Worksheet5/United States/Music.txt"
 1059  ls -l "Worksheet5/United States"
 1060  wc -l "United States/Music.txt"
 1061  ls -l "United States"
 1062  cat "United States/Music.txt"
 1063  cat script.sh 
 1064  vi script.sh 
 1065  cat "United States/Music.txt"
 1066  bash script.sh 
 1067  wc -l "United States/Music.txt"
 1068  vi script.sh 
 1069  bash script.sh 
 1070  cat "United States/Music.txt"
 1071  wc -l "United States/Music.txt"
 1072  cat script.sh 
 1073  vi script.sh 
 1074  bash script.sh 
 1075  vi script.sh 
 1076  bash script.sh 
 1077  vi script.sh 
 1078  bash script.sh 
 1079  wc -l "United States/Music.txt"
 1080  vi script.sh 
 1081  bash script.sh 
 1082  wc -l "United States/Music.txt"
 1083  ls -l
 1084  vi script.sh 
 1085  cat ws5.txt 
 1086  histort>cmds.log
 1087  history>cmds.log
